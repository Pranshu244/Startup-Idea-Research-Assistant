{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5FHN7aH4jYmKACWPIGz7v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pranshu244/Startup-Idea-Research-Assistant/blob/main/Chatbot%20_Code/Startup_Idea_Research_Assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X--UjPT60pey"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community langchain-core pypdf"
      ],
      "metadata": {
        "id": "KuptSxH1OK4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-google-genai faiss-cpu tiktoken python-dotenv"
      ],
      "metadata": {
        "id": "mTePrQaL4XSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-text-splitters"
      ],
      "metadata": {
        "id": "PNqspxMpMz8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchainhub langchain-community sentence-transformers"
      ],
      "metadata": {
        "id": "38wq7qd_UtRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"INSERT_YOUR_API_KEY_OF_gemini-2.5-flash\""
      ],
      "metadata": {
        "id": "HO7k7H-15sS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "loader= PyPDFLoader(\"AFTER UPLOADING YOUR DOCUMENT WRITE IT'S NAME (eg:AI_Startup_Document.pdf)\")\n",
        "docs=loader.load()"
      ],
      "metadata": {
        "id": "sIm0iW37JDPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "splitter=RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=50,\n",
        "    )\n",
        "chunks=splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "sYkZuX5PNlkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "embedding=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "Z_3jyTwwRJql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "vector_store=FAISS.from_documents(chunks,embedding)"
      ],
      "metadata": {
        "id": "Yg7crrjwV2I4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever=vector_store.as_retriever(search_type=\"mmr\",search_kwargs={\"k\":5,\"lambda_mult\": 0.7})"
      ],
      "metadata": {
        "id": "jZMu-5MFXD3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "prompt=PromptTemplate(\n",
        "    template=\"\"\"\n",
        "      You are a helpful research assistant who responds to the user as a friendly companion.\n",
        "      Your job is to compare the user's startup idea (provided in the context) with existing companies.\n",
        "      You will help improve their idea and offer thoughtful, constructive suggestions. Stay focused on startup-related topics.\n",
        "      If the user tries to go off-topic, politely respond that your role is to assist only with startup research and idea development.\n",
        "      You can discuss startups, but not unrelated subjects. Always begin your response directly with the answer ‚Äî do not include greetings\n",
        "      as it is a continued chat but if user greet you then greet him then don ot start the answer automatically. Listen to his query then answer.\n",
        "      Never abuse and never say any inappropirate terms , be polite, no bad language and misbehave even if user aangry.\n",
        "\n",
        "      {context}\n",
        "      Question:{question}\n",
        "    \"\"\",\n",
        "    input_variables=[\"context\",\"question\"]\n",
        ")"
      ],
      "metadata": {
        "id": "oxMiDK4kalHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "model = ChatGoogleGenerativeAI(\n",
        "                    model=\"gemini-2.5-flash\",\n",
        "                    temperature=0.5,\n",
        "                    timeout=30\n",
        "                    )"
      ],
      "metadata": {
        "id": "_fmMVcHuekcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableLambda,RunnablePassthrough,RunnableParallel\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "parser=StrOutputParser()"
      ],
      "metadata": {
        "id": "wkVWh33FpRiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(retrieved_docs):\n",
        "  context_text=\"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
        "  return context_text"
      ],
      "metadata": {
        "id": "i-5FK0bQgl3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parallel_chain= RunnableParallel({\n",
        "    \"context\" : retriever|RunnableLambda(format_docs),\n",
        "    \"question\" : RunnablePassthrough()\n",
        "})"
      ],
      "metadata": {
        "id": "WxqVcrHkr4JP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_chain=parallel_chain|prompt|model|parser"
      ],
      "metadata": {
        "id": "GjFvkkcAsyEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def respond(message, history):\n",
        "    try:\n",
        "        reply = main_chain.invoke(message)\n",
        "    except Exception as e:\n",
        "        reply = f\"‚ö†Ô∏è Error: {type(e).__name__}: {e}\"\n",
        "    history.append((message, reply))\n",
        "    return history, history\n",
        "\n",
        "with gr.Blocks(css=\"\"\"\n",
        "body {background: linear-gradient(135deg, #ffcc70, #ff8c42);}\n",
        "h1 {text-align: center; font-style: italic; font-weight: bold; color: #333;}\n",
        "#chatbot {border-radius: 12px; background-color: #fffaf0;}\n",
        "#msg-box {width: 75%; margin: auto;}\n",
        "button {background-color: #ff8c42 !important; color: white !important; border-radius: 8px;}\n",
        "label {font-weight: bold; color: #ff5722; font-size: 16px;}\n",
        "\"\"\") as demo:\n",
        "    gr.HTML(\"<h1>üöÄ Startup Idea Research Assistant</h1>\")\n",
        "    chatbot = gr.Chatbot(label=\"üí¨ Chatbox\", height=500, show_copy_button=True, elem_id=\"chatbot\")\n",
        "    msg = gr.Textbox(label=\"‚úçÔ∏è Your Question\", placeholder=\"Type your question here...\", elem_id=\"msg-box\")\n",
        "    with gr.Row():\n",
        "        submit = gr.Button(\"Submit\")\n",
        "        clear = gr.Button(\"Clear\")\n",
        "    submit.click(respond, [msg, chatbot], [chatbot, chatbot])\n",
        "    msg.submit(respond, [msg, chatbot], [chatbot, chatbot])\n",
        "    clear.click(lambda: [], None, chatbot)\n",
        "\n",
        "demo.launch(share=True, debug=True)\n"
      ],
      "metadata": {
        "id": "QFvCtQKZPtQE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}